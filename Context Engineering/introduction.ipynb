{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eae6432",
   "metadata": {},
   "source": [
    "# **Introduction: `Context Engineering`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae6507",
   "metadata": {},
   "source": [
    "**`‚ÄúContext Engineering‚Äù`** is a newer, broader idea in the world of prompt-based / agent-based AI systems. It builds on prompt engineering, but adds system design around *what* the model sees, *how* it evolves, and *what* gets kept or removed. I‚Äôll explain what it is, how it works, key strategies, and a concrete example.\n",
    "\n",
    "\n",
    "\n",
    "## **What is Context Engineering:**\n",
    "\n",
    "From the sources:\n",
    "\n",
    "* According to DataCamp: <u>*‚ÄúContext engineering is the practice of designing systems that decide what information an AI model sees before it generates a response.‚Äù* </u>\n",
    "* According to LangChain (blog): it‚Äôs <u>*‚Äúthe art and science of filling the context window with just the right information at each step of an agent‚Äôs trajectory.‚Äù*</u>\n",
    "\n",
    "So it‚Äôs about:\n",
    "\n",
    "1. **Selecting** which kinds of context are relevant (instructions, memory, tools, retrieved external knowledge, etc.).\n",
    "2. **Managing** that context as things evolve (over multiple steps, tool calls, long-running conversation) so that the model doesn‚Äôt get swamped, confused, or distracted.\n",
    "3. **Formatting** or organizing the context so it's helpful and usable to the model.\n",
    "4. **Persisting / retrieving / compressing** past information when needed.\n",
    "\n",
    "\n",
    "\n",
    "## **How It Works ‚Äî Key Components & Strategies:**\n",
    "\n",
    "From LangChain‚Äôs blog, there are 4 major strategy categories for agent / long-running systems: **Write, Select, Compress, Isolate**. \n",
    "\n",
    "Here‚Äôs a breakdown:\n",
    "\n",
    "| Strategy     | Purpose                                                                                                                      | Techniques / Examples                                                                                                                                                                                       |\n",
    "| ------------ | ---------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Write**    | Save context externally (outside the model‚Äôs window) so it can be retrieved later ‚Äî avoid overloading the immediate context. | Use *scratchpads*, *external memory stores*, logs of tool feedback; write summaries of past interactions so important info isn‚Äôt lost.                                                 |\n",
    "| **Select**   | Among all the possible context, choose what‚Äôs most relevant to bring in.                                                     | Retrieval Augmented Generation (RAG) where you pick relevant docs; memory systems that pick recent & pertinent memory; filtering history; selecting most relevant system/tool instructions. |\n",
    "| **Compress** | Shrink context (summarization / abstraction) so you can keep core ideas without exceeding context limits.                    | Summarizing long tool call feedback; compressing conversation history; generating abstractions or meta-memories. [2])                                                                      |\n",
    "| **Isolate**  | Separating context types or keeping ‚Äúclean‚Äù contexts so that irrelevant noise or conflicting info don‚Äôt degrade performance. | Running sub-agents with their own context, sandboxing parts of context, isolating tool outputs, having separate memory for different tasks or topics.                               |\n",
    "\n",
    "Also, from DataCamp: context engineering involves multiple **types of context** that need to be managed: `system instructions`, `conversation history & preferences`, `retrieved documents`, `available tools` & `their definitions`, `real-time API data`, etc. \n",
    "\n",
    "\n",
    "\n",
    "## **When Context Engineering vs Prompt Engineering:**\n",
    "\n",
    "* Prompt engineering is about *how you phrase* a particular input/task. One‚Äêshot instructions etc.\n",
    "* Context engineering is at a larger scale: how do you provide *all* necessary information over time, how do you manage memory & tools, how do you adapt context as task evolves. \n",
    "\n",
    "\n",
    "\n",
    "## **A Concrete Example:**\n",
    "\n",
    "Let‚Äôs build an example to illustrate how context engineering helps:\n",
    "\n",
    "### **Scenario**\n",
    "\n",
    "Suppose you are building a customer support AI agent. The agent supports users over multiple sessions, can pull up product info, past tickets, user preferences, and perform tasks that require external APIs (e.g. check order status, initiate refund).\n",
    "\n",
    "### **Without good context engineering**\n",
    "\n",
    "* Every time user contacts, you send the system prompt + latest user query + tool descriptions.\n",
    "* No memory of past tickets / preferences ‚Üí user has to repeat things.\n",
    "* If the conversation gets long, the agent‚Äôs context window may overflow; older context may push out important instructions or user preferences.\n",
    "* Tool feedback (what the APIs returned before) may clutter the conversation history, confusing the agent.\n",
    "\n",
    "### **With context engineering**\n",
    "\n",
    "You would design the system architecture to include:\n",
    "\n",
    "1. **Memory / Persistence (Write)**\n",
    "\n",
    "   * Keep long-term memory of user profile: preferences, past orders, issues resolved.\n",
    "   * Keep scratchpad of ongoing conversation (short term).\n",
    "\n",
    "2. **Selection**\n",
    "\n",
    "   * For each new user query, retrieve from memory only the parts relevant: maybe if they ask about a product, fetch past tickets about that product.\n",
    "   * Only carry latest few turns of conversation in immediate context.\n",
    "\n",
    "3. **Compression**\n",
    "\n",
    "   * Summarize past resolved tickets or long conversations into compact summaries (e.g., ‚ÄúUser prefers email over chat,‚Äù or ‚ÄúIssue with defective parts last time‚Äù)\n",
    "   * Compress tool feedback; don‚Äôt send full JSON output if only a part is needed.\n",
    "\n",
    "4. **Isolation**\n",
    "\n",
    "   * Separate contexts: e.g. order help context, billing context, product info context.\n",
    "   * Use sub-agents for specialized tasks (one that handles refunds, another that handles technical issues), each has its own limited relevant memory or context.\n",
    "\n",
    "5. **Formatting / Tools & System Instructions**\n",
    "\n",
    "   * Have system instructions that define policies (e.g. tone, privacy).\n",
    "   * Include definitions of tools the agent can call (APIs) so model knows how to use them.\n",
    "   * Format how retrieved documents are included (e.g. ‚ÄúHere is relevant product spec: ‚Ä¶‚Äù) vs how privileges or preferences are expressed.\n",
    "\n",
    "### **What happens in practice**\n",
    "\n",
    "When user comes back with: ‚ÄúHi, it‚Äôs me again. I had a problem with the XYZ model; it didn‚Äôt charge fully. Also I want a refund.‚Äù\n",
    "\n",
    "* The system pulls up their profile (knows they prefer email).\n",
    "* It retrieves past tickets related to model XYZ.\n",
    "* It retrieves tool definitions for refund APIs.\n",
    "* It compresses old conversations so only summaries are in context.\n",
    "* Immediate past few user/agent turns are in context for flow.\n",
    "* The system prompt includes instructions about tone, privacy, etc.\n",
    "\n",
    "This keeps the prompt clear, relevant, not flooded with unnecessary info, and enables the agent to respond appropriately (e.g. apologize, fetch order status, initiate refund) without confusion or repeating questions.\n",
    "\n",
    "\n",
    "\n",
    "## **Benefits & Risks**\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Better relevance and accuracy (agent has what it needs).\n",
    "* Improved user experience (less repetition, more coherence).\n",
    "* Efficiency: avoid sending huge contexts ‚Üí cost & latency savings.\n",
    "* Scaling: systems that work over many turns, with many tools, many users.\n",
    "\n",
    "**Risks / Challenges:**\n",
    "\n",
    "* Designing what is relevant vs what isn‚Äôt can be tricky.\n",
    "* Irrelevant context or outdated memory can hurt more than help (\"context poisoning\").\n",
    "* Deciding when to compress vs drop info.\n",
    "* Privacy/security: memory & context may include sensitive info. Care needed.\n",
    "* Complexity: requires infrastructure (memory stores, retrieval, summarization) rather than just writing prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effc77d",
   "metadata": {},
   "source": [
    "![context_eng](context_eng.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a68886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2db492b",
   "metadata": {},
   "source": [
    "## **What happen if Context Engineering not handle properly:**\n",
    "\n",
    "Excellent follow-up üôå ‚Äî these four are the **failure modes** that can occur when we do Context Engineering poorly. Let‚Äôs go through them one by one with **clear examples** so you can see how they differ.\n",
    "\n",
    "\n",
    "### **‚ö†Ô∏è 1. Context Poisoning**\n",
    "\n",
    "* **Definition:** `Irrelevant`, `outdated`, or `malicious information` sneaks into the model‚Äôs context and corrupts its outputs.\n",
    "  * Think of it as *‚Äúgarbage in ‚Üí garbage out.‚Äù*\n",
    "\n",
    "* **Example:**\n",
    "    You have an AI agent helping with medical advice. Its memory incorrectly stores:\n",
    "\n",
    "    > ‚ÄúAspirin cures all viral infections.‚Äù\n",
    "    > Now every time the user asks about colds or flu, the agent might confidently recommend aspirin ‚Äî dangerous because poisoned context outweighed the real retrieval sources.\n",
    "\n",
    "    üëâ Context poisoning is often a **security risk** (malicious injection) or a **data hygiene risk** (bad or outdated info persisting in memory).\n",
    "\n",
    "\n",
    "### **‚ö†Ô∏è 2. Context Distraction**\n",
    "\n",
    "* **Definition:** Too much `irrelevant information` floods the context window, distracting the model from what‚Äôs important.\n",
    "  * Think of it as *‚Äúsignal drowned by noise.‚Äù*\n",
    "\n",
    "* **Example:**\n",
    "    User: *‚ÄúWhat is the warranty period for iPhone 15 Pro?‚Äù*\n",
    "    Context given to model:\n",
    "\n",
    "      * 5 pages of unrelated product manuals\n",
    "      * Customer reviews of old iPhone models\n",
    "      * Warranty details for iPads\n",
    "      * **One line** about ‚ÄúiPhone 15 Pro warranty: 1 year‚Äù\n",
    "\n",
    "    The model might focus on iPads or iPhone 14 details and miss the one correct line ‚Üí produces wrong answer.\n",
    "\n",
    "\n",
    "\n",
    "### **‚ö†Ô∏è 3. Context Confusion**\n",
    "\n",
    "* **Definition:** Different parts of the context give **conflicting signals**, leaving the model uncertain which to trust.\n",
    "  * Think of it as *‚Äúcontradictions inside the context.‚Äù*\n",
    "\n",
    "* **Example:**\n",
    "\n",
    "  * Memory summary says: ‚ÄúUser prefers refund via **PayPal**.‚Äù\n",
    "  * Latest tool output says: ‚ÄúRefund method: **Credit Card**.‚Äù\n",
    "  * System instruction says: ‚ÄúAlways use **store credit** by default.‚Äù\n",
    "\n",
    "    Now the agent is confused: should it issue PayPal refund, credit card refund, or store credit?\n",
    "    ‚Üí This can cause errors or unpredictable answers.\n",
    "\n",
    "\n",
    "\n",
    "### **‚ö†Ô∏è 4. Context Clash**\n",
    "\n",
    "* **Definition:** When **different context layers** (`system prompt`, `user prompt`, `retrieved documents`, `memory`) **conflict with each other** and the model doesn‚Äôt know which one takes precedence.\n",
    "  * Think of it as *‚Äúauthority conflict between layers.‚Äù*\n",
    "\n",
    "* **Example:**\n",
    "  * **System prompt:** ‚ÄúAlways be formal and polite.‚Äù\n",
    "  * **Memory context:** ‚ÄúUser prefers casual tone.‚Äù\n",
    "  * **User prompt:** ‚ÄúPlease explain this in a super casual way.‚Äù\n",
    "\n",
    "    The model is caught in a **clash**: should it obey the system rule, the user‚Äôs immediate instruction, or the saved preference?\n",
    "    ‚Üí If not carefully engineered (with rules about precedence), outputs can be inconsistent.\n",
    "\n",
    "\n",
    "\n",
    "### **üîë Quick Summary**\n",
    "\n",
    "| Failure Mode            | Root Cause                                           | Example Symptom                        |\n",
    "| ----------------------- | ---------------------------------------------------- | -------------------------------------- |\n",
    "| **Context Poisoning**   | Bad/malicious info injected                          | Model gives harmful or outdated advice |\n",
    "| **Context Distraction** | Too much irrelevant info                             | Model misses the right answer          |\n",
    "| **Context Confusion**   | Contradictory details in same layer                  | Model gives inconsistent responses     |\n",
    "| **Context Clash**       | Different layers (system vs user vs memory) conflict | Model flip-flops tone or behavior      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a74c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0761700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db382cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc149e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
