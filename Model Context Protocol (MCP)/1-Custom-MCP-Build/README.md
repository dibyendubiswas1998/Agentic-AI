# MCP Example:

![MCP](img.png)


‚úÖ **Let‚Äôs break down the working flow of MCP based on the based on log**
```log
    INFO:llm:Initializing AzureChatOpenAI with model=gpt-4o-ocr, temperature=0.9
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:mcp.client.streamable_http:Received session ID: 281e3482ae24487e8093ad904de38e50
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: GET http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 202 Accepted"
    INFO:httpx:HTTP Request: GET http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: DELETE http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: DELETE http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    Successfully loaded tools: ['addition', 'subtraction', 'multiplication', 'division', 'wheather']
    INFO:httpx:HTTP Request: POST https://aiqwiphub9846884880.cognitiveservices.azure.com/openai/deployments/gpt-4o-ocr/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST https://aiqwiphub9846884880.cognitiveservices.azure.com/openai/deployments/gpt-4o-ocr/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST https://aiqwiphub9846884880.cognitiveservices.azure.com/openai/deployments/gpt-4o-ocr/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
    Math response: The result of \((3 + 5) \times 12\) is \(96\).
    INFO:httpx:HTTP Request: POST https://aiqwiphub9846884880.cognitiveservices.azure.com/openai/deployments/gpt-4o-ocr/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:mcp.client.streamable_http:Received session ID: 08d73d4f95e0419e87dd927c41a74209
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: GET http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 202 Accepted"
    INFO:httpx:HTTP Request: GET http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: POST http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: DELETE http://localhost:8000/mcp "HTTP/1.1 307 Temporary Redirect"
    INFO:httpx:HTTP Request: DELETE http://localhost:8000/mcp/ "HTTP/1.1 200 OK"
    INFO:httpx:HTTP Request: POST https://aiqwiphub9846884880.cognitiveservices.azure.com/openai/deployments/gpt-4o-ocr/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
    Weather response: The weather in California is sunny.
```

This is what‚Äôs happening *behind the scenes* when your **LLM agent interacts with MCP tools (servers)** using **MCP Client** over HTTP + SSE (or HTTP with session management).

---

## üöÄ **MCP Working Flow**

### 1Ô∏è‚É£ **Client initiates a tool request**

üëâ Your LLM (via MCP client) sends a **JSON-RPC request** to an MCP server:

```json
{
  "jsonrpc": "2.0",
  "method": "addition",
  "params": {"a": 3, "b": 5},
  "id": "abc123"
}
```

‚û° This is sent over **HTTP POST** to `http://localhost:8000/mcp`.

---

### 2Ô∏è‚É£ **Redirect & session management**

üëâ The server responds with:

```
HTTP/1.1 307 Temporary Redirect
Location: /mcp/
```

‚û° The MCP client follows this redirect ‚Üí starts working on the correct endpoint (`/mcp/`).

üëâ A session ID is generated:

```
INFO: Received session ID: 81f20cd1fed947b985cc1c7eb3dee9a4
```

‚û° **Purpose**:

* Session ID helps track tool calls, context, or tool chain execution for that session.

---

### 3Ô∏è‚É£ **Server processes the tool call**

üëâ The server accepts the task:

```
HTTP/1.1 202 Accepted
```

‚û° Means the server **queued or started** processing the request.

üëâ Client polls for result:

```
GET /mcp/ ‚Üí 200 OK
```

‚û° MCP client fetches final result when ready.

---

### 4Ô∏è‚É£ **Server sends the result**

‚úÖ Example result:

```
Math response: The result of (3 + 5) √ó 12 is 96.
```

‚úÖ Example weather response:

```
Weather response: The weather in California is sunny.
```

‚û° The server has processed tools like `addition`, `multiplication`, or `weather`, and sent the final JSON-RPC **result** back.

---

### 5Ô∏è‚É£ **Session cleanup**

üëâ When finished:

```
DELETE /mcp ‚Üí 200 OK
```

‚û° The session is closed; server frees resources, and context is cleared (unless persistent memory is configured).

---

## üåê **Summary of Flow**

```
LLM ‚Üí MCP Client ‚Üí MCP Server (via HTTP + JSON-RPC)
‚Üì
Tool call request ‚Üí Session established ‚Üí Task processed
‚Üì
Streaming/polling result ‚Üí Result sent ‚Üí Session closed
```

---

## üß† **Why this is powerful**

* **Dynamic tool calling**: LLM can call any tool without pre-defining API contracts.
* **Session-based context**: Each chain of tool calls can share state.
* **Secure & modular**: Tools are isolated; each server handles its own logic.